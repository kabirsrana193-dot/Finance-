# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wF5wIUk93YjwGVZbtRX7HUEr3Tm5PQjQ
"""

import streamlit as st
from gnews import GNews
from transformers import pipeline
import pandas as pd
from datetime import datetime

# Page config
st.set_page_config(
    page_title="Finance News Dashboard",
    page_icon="ðŸ“ˆ",
    layout="wide"
)

# ------------------------
# 1. Setup (with caching)
# ------------------------
@st.cache_resource
def load_sentiment_model():
    """Load FinBERT model once and cache it"""
    return pipeline("sentiment-analysis",
                   model="yiyanghkust/finbert-tone",
                   tokenizer="yiyanghkust/finbert-tone")

@st.cache_resource
def setup_gnews():
    """Setup GNews client"""
    return GNews(language='en', country='in', max_results=30)

# Finance-related keywords
finance_keywords = [
    "stock market", "NSE", "BSE", "Sensex", "Nifty",
    "RBI", "banking", "earnings", "IPO", "finance",
    "quarterly results", "dividend", "merger", "acquisition", "sales", "revenue",
    "inflation", "rate"
]

# Initialize
news_client = setup_gnews()
finbert = load_sentiment_model()

def get_sentiment_finbert(text):
    """Get sentiment using FinBERT"""
    try:
        result = finbert(text[:512])[0]
        return result['label']
    except Exception as e:
        return "Error"

@st.cache_data(ttl=300)  # Cache for 5 minutes
def fetch_finance_news():
    """Fetch and process finance news"""
    all_articles = []
    progress_bar = st.progress(0)
    status_text = st.empty()

    for idx, keyword in enumerate(finance_keywords):
        status_text.text(f"Fetching news for: {keyword}")
        try:
            articles = news_client.get_news(keyword)
            if articles:
                all_articles.extend(articles)
        except Exception as e:
            st.warning(f"Error fetching for {keyword}: {e}")
        progress_bar.progress((idx + 1) / len(finance_keywords))

    progress_bar.empty()
    status_text.empty()

    # Remove duplicates by title
    unique_articles = {article['title'].strip(): article for article in all_articles}
    articles_list = list(unique_articles.values())

    # Process articles
    data = []
    for article in articles_list[:30]:  # Get top 30
        title = article['title'].strip()
        source = article['publisher']['title'] if article.get('publisher') else "Unknown"
        url = article['url']
        sentiment = get_sentiment_finbert(title)

        data.append({
            "Title": title,
            "Source": source,
            "Sentiment": sentiment,
            "Link": url
        })

    return pd.DataFrame(data)

# ------------------------
# 2. Streamlit UI
# ------------------------
st.title("ðŸ“ˆ Finance News Dashboard")
st.markdown("Real-time Indian finance news with sentiment analysis powered by FinBERT")
st.divider()

# Sidebar
with st.sidebar:
    st.header("Settings")
    auto_refresh = st.checkbox("Auto-refresh (5 min)", value=False)
    sentiment_filter = st.multiselect(
        "Filter by Sentiment",
        ["Positive", "Negative", "Neutral"],
        default=["Positive", "Negative", "Neutral"]
    )
    st.divider()
    st.info("ðŸ’¡ Data refreshes every 5 minutes when cached")

# Main content
col1, col2, col3 = st.columns([2, 2, 1])
with col1:
    st.metric("Data Source", "GNews API")
with col2:
    st.metric("Last Updated", datetime.now().strftime("%H:%M:%S"))
with col3:
    if st.button("ðŸ”„ Refresh Now", use_container_width=True):
        st.cache_data.clear()
        st.rerun()

# Fetch news
with st.spinner("Fetching latest finance news..."):
    df = fetch_finance_news()

if df.empty:
    st.warning("No articles found. Try refreshing again.")
else:
    # Filter by sentiment
    df_filtered = df[df['Sentiment'].str.capitalize().isin(sentiment_filter)]

    # Display statistics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Articles", len(df_filtered))
    with col2:
        positive_count = len(df_filtered[df_filtered['Sentiment'].str.lower() == 'positive'])
        st.metric("Positive", positive_count, delta=None)
    with col3:
        negative_count = len(df_filtered[df_filtered['Sentiment'].str.lower() == 'negative'])
        st.metric("Negative", negative_count, delta=None)
    with col4:
        neutral_count = len(df_filtered[df_filtered['Sentiment'].str.lower() == 'neutral'])
        st.metric("Neutral", neutral_count, delta=None)

    st.divider()

    # Display articles
    for idx, row in df_filtered.iterrows():
        # Color based on sentiment
        if row['Sentiment'].lower() == 'positive':
            sentiment_color = "ðŸŸ¢"
        elif row['Sentiment'].lower() == 'negative':
            sentiment_color = "ðŸ”´"
        else:
            sentiment_color = "ðŸŸ¡"

        with st.container():
            col1, col2 = st.columns([0.05, 0.95])
            with col1:
                st.markdown(f"### {sentiment_color}")
            with col2:
                st.markdown(f"**{row['Title']}**")
                st.caption(f"Source: {row['Source']} | Sentiment: {row['Sentiment']}")
                st.markdown(f"[Read Article]({row['Link']})")
            st.divider()

# Auto-refresh
if auto_refresh:
    import time
    time.sleep(300)  # 5 minutes
    st.rerun()