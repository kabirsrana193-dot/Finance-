# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wF5wIUk93YjwGVZbtRX7HUEr3Tm5PQjQ
"""

# dashboard.py
from gnews import GNews
from transformers import pipeline
import dash
from dash import html
import dash_bootstrap_components as dbc
from dash.dependencies import Input, Output
import pandas as pd

# ------------------------
# 1. Setup GNews client
# ------------------------
news_client = GNews(language='en', country='in', max_results=30)

# 2. Finance-related keywords
finance_keywords = [
    "stock market", "NSE", "BSE", "Sensex", "Nifty",
    "RBI", "banking", "earnings", "IPO", "finance",
    "quarterly results", "dividend", "merger", "acquisition", "sales", "revenue",
    "inflation", "rate"
]

# 3. Load FinBERT sentiment model
finbert = pipeline("sentiment-analysis", model="yiyanghkust/finbert-tone", tokenizer="yiyanghkust/finbert-tone")

def get_sentiment_finbert(text):
    try:
        result = finbert(text[:512])[0]  # truncate to 512 tokens
        return result['label']   # 'positive', 'negative', 'neutral'
    except Exception as e:
        return f"Error: {e}"

# ------------------------
# 4. Global memory for seen titles
# ------------------------
seen_titles_global = set()

def fetch_finance_news():
    global seen_titles_global
    all_articles = []
    for keyword in finance_keywords:
        try:
            articles = news_client.get_news(keyword)
            if articles:
                all_articles.extend(articles)
        except Exception as e:
            print(f"Error fetching for {keyword}: {e}")

    # Remove duplicates by title
    unique_articles = {article['title'].strip(): article for article in all_articles}
    articles_list = list(unique_articles.values())

    # Prepare DataFrame
    data = []
    for article in articles_list[:20]:
        title = article['title'].strip()

        # Skip if already seen
        if title in seen_titles_global:
            continue
        seen_titles_global.add(title)

        source = article['publisher']['title'] if article.get('publisher') else "Unknown"
        url = article['url']
        sentiment = get_sentiment_finbert(title)

        data.append({
            "Title": title,
            "Source": source,
            "Sentiment": sentiment,
            "Link": url
        })
    df = pd.DataFrame(data)
    return df

# ------------------------
# 5. Dash app
# ------------------------
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

app.layout = dbc.Container([
    html.H1("Finance News", style={"textAlign": "center", "marginTop": 20}),
    html.Hr(),
    dbc.Button("Refresh News", id="refresh-button", color="primary", className="mb-3"),
    html.Div(id="news-table")
], fluid=True)

# ------------------------
# 6. Callbacks
# ------------------------
@app.callback(
    Output("news-table", "children"),
    Input("refresh-button", "n_clicks")
)
def update_table(n_clicks):
    if n_clicks is None:
        return "Click 'Refresh News' to load the latest articles."
    df = fetch_finance_news()
    if df.empty:
        return "No new articles found."
    table = dbc.Table.from_dataframe(df, striped=True, bordered=True, hover=True)
    return table

# ------------------------
# 7. Run app
# ------------------------
if __name__ == "__main__":
    app.run(debug=True)